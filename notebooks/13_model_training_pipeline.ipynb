{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# connect to project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# connect to feature store\n",
    "feature_store = project.get_feature_store()\n",
    "feature_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# connect to feature group\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    ")\n",
    "feature_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# create a feature view \n",
    "\n",
    "try:\n",
    "    # create a feature view if it doesnt exist\n",
    "    feature_store.create_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION,\n",
    "        query=feature_group.select_all()\n",
    "    )\n",
    "except:\n",
    "    print(\"Feature view already exists. Skip creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# get feature view\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME,\n",
    "    version=config.FEATURE_VIEW_VERSION\n",
    ")\n",
    "feature_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# fetch data from feature store using feature view\n",
    "ts_data, _ = feature_view.training_data(\n",
    "    description='Time-series hourly taxi rides'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# drop `pickup_ts` column\n",
    "ts_data.drop('pickup_ts', axis=1, inplace=True)\n",
    "\n",
    "# sort by `pickup_location_id` and `pickup_hour`\n",
    "ts_data.sort_values(by=['pickup_location_id', 'pickup_hour'], inplace=True)\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# from src.plot import plot_ts\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "\n",
    "def plot_ts(\n",
    "    ts_data: pd.DataFrame,\n",
    "    locations: Optional[List[int]] = None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Plot time-series data\n",
    "    \"\"\"\n",
    "    ts_data_to_plot = ts_data[ts_data.pickup_location_id.isin(locations)] if locations else ts_data\n",
    "\n",
    "    fig = px.line(\n",
    "        ts_data_to_plot,\n",
    "        x=\"pickup_hour\",\n",
    "        y=\"rides\",\n",
    "        color='pickup_location_id',\n",
    "        template='none',\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_ts(ts_data, locations=[43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting timeseries data into feature and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from src.data import transform_ts_data_into_features_and_target\n",
    "\n",
    "features, targets = transform_ts_data_into_features_and_target(\n",
    "    ts_data,\n",
    "    input_seq_len=24*28, # one month\n",
    "    step_size=23,\n",
    ")\n",
    "\n",
    "features_and_target = features.copy()\n",
    "features_and_target['target_rides_next_hour'] = targets\n",
    "\n",
    "print(f'{features_and_target.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "features_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "features_and_target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "features_and_target['pickup_hour'] = pd.to_datetime(features_and_target['pickup_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "from src.data_split import train_test_split\n",
    "\n",
    "# training data -> from January 2022 up until 4 months ago\n",
    "# testing data -> last 3 months\n",
    "\n",
    "# cutoff_date = pd.to_datetime(date.today() - timedelta(days=28*6), utc=True)\n",
    "\n",
    "\n",
    "\n",
    "cutoff_date = pd.to_datetime(datetime.utcnow() - timedelta(days=28*4))\n",
    "\n",
    "# Set the time to midnight\n",
    "cutoff_date = pd.to_datetime(cutoff_date.replace(hour=0, minute=0, second=0, microsecond=0)).tz_localize('UTC')\n",
    "print(f'{cutoff_date=}')\n",
    "\n",
    "# real_current_date = datetime.utcnow()\n",
    "\n",
    "# simulated_current_date = real_current_date - timedelta(days=365)\n",
    "# simulated_current_date = pd.to_datetime(simulated_current_date).floor('H')\n",
    "# print(f\"Simulated current date: {simulated_current_date}\")\n",
    "\n",
    "# # Ensure simulated_current_date has the same timezone as pickup_hour\n",
    "# simulated_current_date = simulated_current_date.tz_localize('UTC')\n",
    "\n",
    "# # Filter out any data after the simulated current date\n",
    "# features_and_target = features_and_target[features_and_target['pickup_hour'] < simulated_current_date]\n",
    "\n",
    "# # Calculate the training/testing cutoff (4 months before simulated date)\n",
    "# cutoff_date = simulated_current_date - timedelta(days=28*4)\n",
    "# cutoff_date = pd.to_datetime(cutoff_date.replace(hour=0, minute=0, second=0, microsecond=0))\n",
    "# print(f\"Training/testing cutoff date: {cutoff_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    features_and_target,\n",
    "    cutoff_date,\n",
    "    target_column_name='target_rides_next_hour'\n",
    ")\n",
    "\n",
    "print(f'{X_train.shape=}')\n",
    "print(f'{y_train.shape=}')\n",
    "print(f'{X_test.shape=}')\n",
    "print(f'{y_test.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import get_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Given a set of hyper-parameters, it trains a model and computes an average validation error based on a TimeSeriesSplit\n",
    "    \"\"\"\n",
    "\n",
    "    # pick hyper-parameters\n",
    "    hyperparams = {\n",
    "        \"metric\": \"mae\",\n",
    "        \"verbose\": -1,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 100),\n",
    "    }\n",
    "\n",
    "    X_train.sort_values('pickup_hour', inplace=True)\n",
    "\n",
    "\n",
    "    tss = TimeSeriesSplit(n_splits=4)\n",
    "    scores = []\n",
    "    for train_index, val_index in tss.split(X_train):\n",
    "\n",
    "        # split data for training and validation\n",
    "        X_train_, X_val_ = X_train.iloc[train_index, :], X_train.iloc[val_index,:]\n",
    "        y_train_, y_val_ = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # train the model\n",
    "        pipeline = get_pipeline(**hyperparams)\n",
    "        pipeline.fit(X_train_, y_train_)\n",
    "\n",
    "        # evaluate the model\n",
    "        y_pred = pipeline.predict(X_val_)\n",
    "        mae = mean_absolute_error(y_val_, y_pred)\n",
    "\n",
    "        scores.append(mae)\n",
    "\n",
    "    \n",
    "    # return the mean score\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(f'{best_params=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pipeline = get_pipeline(**best_params)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f'{test_mae=:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import joblib\n",
    "from src.paths import MODELS_DIR\n",
    "\n",
    "joblib.dump(pipeline, MODELS_DIR / 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopsworks Model schema - format for the input data and output data\n",
    "here we are providing example of input schema and output schema using X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hopsworks Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model_registry = project.get_model_registry()\n",
    "\n",
    "model = model_registry.sklearn.create_model(\n",
    "    name=\"taxi_demand_forecaster_next_hour\",\n",
    "    metrics={\"test_mae\": test_mae},\n",
    "    description=\"LightGBM regressor wiht a bit of hyper-parameter tuning\",\n",
    "    input_example=X_train.sample(),\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "model.save(str(MODELS_DIR / 'model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-WfGCHEar-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
